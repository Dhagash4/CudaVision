{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "## Import"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "from typing import Tuple\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Weights and bias initialization"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "def WeightBaisInit(input_dim: int,output_dim: int) -> Tuple[np.ndarray,np.ndarray]:\n",
    "    \n",
    "    '''\n",
    "    Initialization of weights and bias can be changed further if we need more functionalities\n",
    "    '''\n",
    "    \n",
    "    w_init = np.random.rand(input_dim,output_dim)\n",
    "    b_init = np.random.rand(output_dim,)\n",
    "\n",
    "    return w_init,b_init"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Linear Layer Forward"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "def linear_layer_forward(x: np.ndarray,input_dim: int,output_dim: int):\n",
    "\n",
    "    '''\n",
    "    Computes forward pass for simple linear layer \n",
    "    \n",
    "\n",
    "    Input: \n",
    "    x: Numpy array containing input data, N x H x W we flatten last two dimensions so its N x D\n",
    "    input_dim: Input dimensions of hidden layer\n",
    "    output_dim: Output dimensions of hidden layer\n",
    "    \n",
    "    Output:\n",
    "\n",
    "\n",
    "    output: Numpy array after matrix multiplication, N x M\n",
    "    \n",
    "    '''\n",
    "    \n",
    "    assert(input_dim==x.shape[1])\n",
    "    #Initialize weights and bias for this layer\n",
    "\n",
    "    w,b = WeightBaisInit(input_dim,output_dim)\n",
    "\n",
    "    output =  (x @ w) + b\n",
    "\n",
    "    return output"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Sigmoid Function Forward"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "def sigmoid_activation_forward(x: np.ndarray) -> (np.ndarray):\n",
    "\n",
    "    '''\n",
    "    \n",
    "    Apply sigmoid function on given input\n",
    "    \n",
    "    Input:\n",
    "\n",
    "    x: Numpy array, NxD\n",
    "\n",
    "    Output:\n",
    "\n",
    "    output: Numpy array after sigmoid activation , NxD\n",
    "\n",
    "    '''\n",
    "\n",
    "    #Check if we need to normalize the input before passing to sigmoid\n",
    "\n",
    "    output  = 1 / (1 + np.exp(-x))\n",
    "\n",
    "    return output"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Softmax Layer Forward Pass"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "def softmax_activation_forward(x: np.ndarray) -> (np.ndarray):\n",
    "    '''\n",
    "    \n",
    "    Apply softmax function on given input\n",
    "    \n",
    "    Input:\n",
    "\n",
    "    x: Numpy array, NxD\n",
    "\n",
    "    Output:\n",
    "\n",
    "    output: Numpy array after softmax activation , NxD\n",
    "\n",
    "    '''\n",
    "\n",
    "    #Check if we need to normalize the input before passing to sigmoid\n",
    "\n",
    "    output = np.exp(x)/np.sum(x)\n",
    "\n",
    "    return output"
   ],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.7.10",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.7.10 64-bit ('dl': conda)"
  },
  "interpreter": {
   "hash": "f7881038a8c0c2c5168ac80e20ff544f471faf7d5bc66c5653256549b0169354"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}