{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled1.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "l-FKD5uJUKdy"
      },
      "source": [
        "import torch\n",
        "import torchvision\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch import optim\n",
        "import torchvision.transforms as transforms\n",
        "from torch.utils.data.dataloader import DataLoader\n",
        "from torch.utils.data import random_split\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "from tqdm import tqdm"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T2WqswylUODA",
        "outputId": "f82f4ec3-82bb-4280-aa39-babcc461f960"
      },
      "source": [
        "\n",
        "transform = transforms.Compose([transforms.ToTensor(),\n",
        "                                transforms.Normalize((0.5,), (0.5,))])\n",
        "\n",
        "trainset = torchvision.datasets.CIFAR10(root='./data', train=True, transform=transforms.ToTensor(), download=True)\n",
        "testset = torchvision.datasets.CIFAR10(root='./data', train=False, transform=transforms.ToTensor(), download=True)\n",
        "trainset,validationset = random_split(trainset,[round(0.9 * len(trainset)), round(0.1 * len(trainset))])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UxYTrRJXUPHQ"
      },
      "source": [
        "\n",
        "\n",
        "\n",
        "trainloader = torch.utils.data.DataLoader(trainset, batch_size=128, shuffle=True)\n",
        "\n",
        "testloader = torch.utils.data.DataLoader(testset, batch_size=128, shuffle=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tYwsEjR4V1I-"
      },
      "source": [
        "\n",
        "\n",
        "\n",
        "\n",
        "class Classifier(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.fc1 = nn.Linear(3072, 256)\n",
        "        self.fc2 = nn.Linear(256, 256)\n",
        "        self.fc3 = nn.Linear(256, 64)\n",
        "        self.fc4 = nn.Linear(64, 10)\n",
        "        \n",
        "        \n",
        "    def forward(self, x):\n",
        "        # make sure input tensor is flattened\n",
        "        x = x.view(x.shape[0], -1)\n",
        "        \n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = F.relu(self.fc2(x))\n",
        "        x = F.relu(self.fc3(x))\n",
        "        x = F.log_softmax(self.fc4(x), dim=1)\n",
        "        \n",
        "        return x\n",
        "def count_model_params(model):\n",
        "    \"\"\" Counting the number of learnable parameters in a nn.Module \"\"\"\n",
        "    num_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "    return num_params\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3m9XCpf2WPqe",
        "outputId": "361d2275-e146-4668-c718-3e5b0a405217"
      },
      "source": [
        "model = Classifier()\n",
        "# model = model.to(device)\n",
        "\n",
        "# criterion = nn.NLLLoss().to(device)\n",
        "criterion = nn.NLLLoss()\n",
        "lr = 0.00083\n",
        "optimizer = optim.Adam(model.parameters(), lr= lr)\n",
        "\n",
        "epochs = 50\n",
        "steps = 0\n",
        "cm = [ [ 0 for i in range(10) ] for j in range(10) ]\n",
        "\n",
        "\n",
        "train_losses, test_losses = [], []\n",
        "train_acc, test_acc =[],[]\n",
        "  \n",
        "for e in range(epochs):\n",
        "\n",
        "    running_loss = 0\n",
        "    accuracy2 = 0\n",
        "\n",
        "    for images, labels in trainloader:\n",
        "        # images= images.to(device)\n",
        "        # labels = labels.to(device)\n",
        "        \n",
        "        optimizer.zero_grad()\n",
        "        log_ps = model(images)        \n",
        "        loss = criterion(log_ps, labels)\n",
        "        loss.backward()\n",
        "        \n",
        "        optimizer.step()\n",
        "        with torch.no_grad(): \n",
        "          model.eval()\n",
        "          log_ps2 = log_ps.clone().detach()               \n",
        "          ps2 = torch.exp(log_ps2)\n",
        "          top_p2, top_class2 = ps2.topk(1, dim=1)\n",
        "          equals2 = top_class2 == labels.view(*top_class2.shape)\n",
        "          accuracy2 += torch.mean(equals2.type(torch.FloatTensor))\n",
        "\n",
        "\n",
        "\n",
        "        model.train()        \n",
        "        running_loss += loss.item()\n",
        "\n",
        "    else:\n",
        "        test_loss = 0\n",
        "        accuracy = 0\n",
        "        \n",
        "        # Turn off gradients for validation, saves memory and computations\n",
        "        with torch.no_grad():\n",
        "            \n",
        "            model.eval()\n",
        "            for images, labels in testloader:\n",
        "                # images= images.to(device)\n",
        "                # labels = labels.to(device)             \n",
        "                log_ps = model(images)\n",
        "                test_loss += criterion(log_ps, labels)\n",
        "                \n",
        "                ps = torch.exp(log_ps)\n",
        "                top_p, top_class = ps.topk(1, dim=1)\n",
        "                equals = top_class == labels.view(*top_class.shape)\n",
        "                accuracy += torch.mean(equals.type(torch.FloatTensor))\n",
        "                # cm += confusion_matrix(labels.view(*top_class.shape).cpu(), top_class.cpu())\n",
        "                \n",
        "\n",
        "        \n",
        "        model.train()\n",
        "        \n",
        "        train_losses.append(running_loss/len(trainloader))\n",
        "        test_losses.append(test_loss/len(testloader))\n",
        "        train_acc.append(accuracy2/len(trainloader))\n",
        "        test_acc.append(accuracy/len(testloader))\n",
        "        # Norm_grad.append(total_norm)\n",
        "        \n",
        "\n",
        "        print(\"Epoch: {}/{}.. \".format(e+1, epochs),\n",
        "              \"Training Loss: {:.3f}.. \".format(train_losses[-1]),\n",
        "              \"Train Accuracy: {:.3f}\".format(accuracy2/len(trainloader)),\n",
        "              \"Test Loss: {:.3f}.. \".format(test_losses[-1]),\n",
        "              \"Test Accuracy: {:.3f}\".format(accuracy/len(testloader)))\n",
        "# print(cm)\n",
        "        \n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 1/50..  Training Loss: 1.921..  Train Accuracy: 0.294 Test Loss: 1.742..  Test Accuracy: 0.373\n",
            "Epoch: 2/50..  Training Loss: 1.722..  Train Accuracy: 0.378 Test Loss: 1.661..  Test Accuracy: 0.405\n",
            "Epoch: 3/50..  Training Loss: 1.632..  Train Accuracy: 0.414 Test Loss: 1.609..  Test Accuracy: 0.422\n",
            "Epoch: 4/50..  Training Loss: 1.571..  Train Accuracy: 0.434 Test Loss: 1.562..  Test Accuracy: 0.435\n",
            "Epoch: 5/50..  Training Loss: 1.530..  Train Accuracy: 0.454 Test Loss: 1.506..  Test Accuracy: 0.467\n",
            "Epoch: 6/50..  Training Loss: 1.489..  Train Accuracy: 0.468 Test Loss: 1.510..  Test Accuracy: 0.465\n",
            "Epoch: 7/50..  Training Loss: 1.453..  Train Accuracy: 0.481 Test Loss: 1.476..  Test Accuracy: 0.469\n",
            "Epoch: 8/50..  Training Loss: 1.429..  Train Accuracy: 0.489 Test Loss: 1.453..  Test Accuracy: 0.490\n",
            "Epoch: 9/50..  Training Loss: 1.397..  Train Accuracy: 0.501 Test Loss: 1.434..  Test Accuracy: 0.484\n",
            "Epoch: 10/50..  Training Loss: 1.374..  Train Accuracy: 0.512 Test Loss: 1.441..  Test Accuracy: 0.486\n",
            "Epoch: 11/50..  Training Loss: 1.344..  Train Accuracy: 0.522 Test Loss: 1.431..  Test Accuracy: 0.492\n",
            "Epoch: 12/50..  Training Loss: 1.320..  Train Accuracy: 0.529 Test Loss: 1.401..  Test Accuracy: 0.503\n",
            "Epoch: 13/50..  Training Loss: 1.298..  Train Accuracy: 0.537 Test Loss: 1.425..  Test Accuracy: 0.502\n",
            "Epoch: 14/50..  Training Loss: 1.282..  Train Accuracy: 0.541 Test Loss: 1.389..  Test Accuracy: 0.508\n",
            "Epoch: 15/50..  Training Loss: 1.267..  Train Accuracy: 0.548 Test Loss: 1.417..  Test Accuracy: 0.496\n",
            "Epoch: 16/50..  Training Loss: 1.243..  Train Accuracy: 0.557 Test Loss: 1.426..  Test Accuracy: 0.495\n",
            "Epoch: 17/50..  Training Loss: 1.222..  Train Accuracy: 0.564 Test Loss: 1.404..  Test Accuracy: 0.506\n",
            "Epoch: 18/50..  Training Loss: 1.206..  Train Accuracy: 0.570 Test Loss: 1.402..  Test Accuracy: 0.510\n",
            "Epoch: 19/50..  Training Loss: 1.186..  Train Accuracy: 0.577 Test Loss: 1.424..  Test Accuracy: 0.503\n",
            "Epoch: 20/50..  Training Loss: 1.165..  Train Accuracy: 0.582 Test Loss: 1.398..  Test Accuracy: 0.513\n",
            "Epoch: 21/50..  Training Loss: 1.153..  Train Accuracy: 0.590 Test Loss: 1.381..  Test Accuracy: 0.515\n",
            "Epoch: 22/50..  Training Loss: 1.134..  Train Accuracy: 0.594 Test Loss: 1.399..  Test Accuracy: 0.520\n",
            "Epoch: 23/50..  Training Loss: 1.119..  Train Accuracy: 0.600 Test Loss: 1.371..  Test Accuracy: 0.520\n",
            "Epoch: 24/50..  Training Loss: 1.100..  Train Accuracy: 0.606 Test Loss: 1.393..  Test Accuracy: 0.519\n",
            "Epoch: 25/50..  Training Loss: 1.079..  Train Accuracy: 0.615 Test Loss: 1.408..  Test Accuracy: 0.519\n",
            "Epoch: 26/50..  Training Loss: 1.065..  Train Accuracy: 0.618 Test Loss: 1.424..  Test Accuracy: 0.519\n",
            "Epoch: 27/50..  Training Loss: 1.053..  Train Accuracy: 0.623 Test Loss: 1.409..  Test Accuracy: 0.517\n",
            "Epoch: 28/50..  Training Loss: 1.030..  Train Accuracy: 0.631 Test Loss: 1.394..  Test Accuracy: 0.537\n",
            "Epoch: 29/50..  Training Loss: 1.024..  Train Accuracy: 0.635 Test Loss: 1.402..  Test Accuracy: 0.519\n",
            "Epoch: 30/50..  Training Loss: 1.009..  Train Accuracy: 0.639 Test Loss: 1.429..  Test Accuracy: 0.518\n",
            "Epoch: 31/50..  Training Loss: 0.991..  Train Accuracy: 0.647 Test Loss: 1.423..  Test Accuracy: 0.523\n",
            "Epoch: 32/50..  Training Loss: 0.972..  Train Accuracy: 0.653 Test Loss: 1.451..  Test Accuracy: 0.521\n",
            "Epoch: 33/50..  Training Loss: 0.965..  Train Accuracy: 0.655 Test Loss: 1.448..  Test Accuracy: 0.522\n",
            "Epoch: 34/50..  Training Loss: 0.948..  Train Accuracy: 0.661 Test Loss: 1.475..  Test Accuracy: 0.516\n",
            "Epoch: 35/50..  Training Loss: 0.935..  Train Accuracy: 0.664 Test Loss: 1.463..  Test Accuracy: 0.520\n",
            "Epoch: 36/50..  Training Loss: 0.919..  Train Accuracy: 0.671 Test Loss: 1.522..  Test Accuracy: 0.517\n",
            "Epoch: 37/50..  Training Loss: 0.906..  Train Accuracy: 0.676 Test Loss: 1.455..  Test Accuracy: 0.536\n",
            "Epoch: 38/50..  Training Loss: 0.889..  Train Accuracy: 0.682 Test Loss: 1.542..  Test Accuracy: 0.510\n",
            "Epoch: 39/50..  Training Loss: 0.879..  Train Accuracy: 0.686 Test Loss: 1.508..  Test Accuracy: 0.523\n",
            "Epoch: 40/50..  Training Loss: 0.871..  Train Accuracy: 0.687 Test Loss: 1.474..  Test Accuracy: 0.526\n",
            "Epoch: 41/50..  Training Loss: 0.857..  Train Accuracy: 0.694 Test Loss: 1.567..  Test Accuracy: 0.509\n",
            "Epoch: 42/50..  Training Loss: 0.851..  Train Accuracy: 0.694 Test Loss: 1.527..  Test Accuracy: 0.521\n",
            "Epoch: 43/50..  Training Loss: 0.825..  Train Accuracy: 0.704 Test Loss: 1.542..  Test Accuracy: 0.527\n",
            "Epoch: 44/50..  Training Loss: 0.821..  Train Accuracy: 0.705 Test Loss: 1.585..  Test Accuracy: 0.520\n",
            "Epoch: 45/50..  Training Loss: 0.812..  Train Accuracy: 0.707 Test Loss: 1.619..  Test Accuracy: 0.509\n",
            "Epoch: 46/50..  Training Loss: 0.798..  Train Accuracy: 0.713 Test Loss: 1.589..  Test Accuracy: 0.507\n",
            "Epoch: 47/50..  Training Loss: 0.783..  Train Accuracy: 0.721 Test Loss: 1.660..  Test Accuracy: 0.509\n",
            "Epoch: 48/50..  Training Loss: 0.771..  Train Accuracy: 0.723 Test Loss: 1.611..  Test Accuracy: 0.514\n",
            "Epoch: 49/50..  Training Loss: 0.768..  Train Accuracy: 0.723 Test Loss: 1.665..  Test Accuracy: 0.519\n",
            "Epoch: 50/50..  Training Loss: 0.755..  Train Accuracy: 0.731 Test Loss: 1.658..  Test Accuracy: 0.515\n"
          ]
        }
      ]
    }
  ]
}